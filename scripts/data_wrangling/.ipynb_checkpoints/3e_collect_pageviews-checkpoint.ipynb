{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using wmfdata v1.0.3, but v1.0.4 is available.\n",
      "\n",
      "To update, run `pip install --upgrade git+https://github.com/neilpquinn/wmfdata.git@release`.\n",
      "\n",
      "To see the changes, refer to https://github.com/neilpquinn/wmfdata/blob/release/CHANGELOG.md\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import wmfdata as wmf\n",
    "from wmfdata import charting, mariadb, hive, spark\n",
    "from wmfdata.utils import pct_str, pd_display_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv(\"../../data/processed/query_results/content_quality/indonesia/CQ_all_articles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get pageviews for all articles in csv containing articles from various wikis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mediawiki_page_history - https://wikitech.wikimedia.org/wiki/Analytics/Data_Lake/Edits/Mediawiki_page_history\n",
    "#fyi you need to truncate. Recommend 30 day period: https://meta.wikimedia.org/wiki/Research:Autoconfirmed_article_creation_trial#H14:_The_survival_rate_of_newly_created_articles_by_autoconfirmed_users_will_remain_stable\n",
    "# Article deletion rates and article timespan - http://files.grouplens.org/papers/lam_group2009_wikipedia-longer-tail.pdf\n",
    "\n",
    "#note - archive table in Mariadb holds revisions for pages that have been deleted\n",
    "\n",
    "#snapshot = \"{MWH_SNAPSHOT}\"\n",
    "#AND event_timestamp >=\"{contest_start}\"\n",
    "#AND event_timestamp <\"{contest_end}\"\n",
    "        \n",
    "pageview_articles = []\n",
    "pageview_all_articles = []\n",
    "\n",
    "def get_pageviews_hive(df):\n",
    "\n",
    "    pv_indonesia_users_july = \"\"\"\n",
    "    SELECT \n",
    "      project,\n",
    "      page_id,\n",
    "      page_title,\n",
    "      SUM(view_count) as july_view_count_internal\n",
    "    FROM  wmf.pageview_hourly pvh\n",
    "    LEFT JOIN canonical_data.wikis cdw\n",
    "        ON CONCAT(cdw.language_code, '.', cdw.database_group) = pvh.project \n",
    "    WHERE\n",
    "        pvh.agent_type='user'\n",
    "        AND pvh.country_code = 'ID'\n",
    "        AND pvh.year = 2020\n",
    "        AND pvh.month = 7\n",
    "        AND pvh.page_id IN {ids}\n",
    "        AND cdw.database_group = 'wikipedia'\n",
    "        AND cdw.language_code = '{language_code}'\n",
    "    GROUP BY \n",
    "      project, page_id, page_title\n",
    "    \"\"\"\n",
    "    \n",
    "    pv_all_users_july = \"\"\"\n",
    "    SELECT \n",
    "      project,\n",
    "      page_id,\n",
    "      page_title,\n",
    "      SUM(view_count) as july_view_count_internal\n",
    "    FROM  wmf.pageview_hourly pvh\n",
    "    LEFT JOIN canonical_data.wikis cdw\n",
    "        ON CONCAT(cdw.language_code, '.', cdw.database_group) = pvh.project \n",
    "    WHERE\n",
    "        pvh.agent_type='user'\n",
    "        AND pvh.year = 2020\n",
    "        AND pvh.month = 7\n",
    "        AND pvh.page_id IN {ids}\n",
    "        AND cdw.database_group = 'wikipedia'\n",
    "        AND cdw.language_code = '{language_code}'\n",
    "    GROUP BY \n",
    "      project, page_id, page_title\n",
    "    \"\"\"\n",
    "        \n",
    "    for wiki in df['language_code'].unique():\n",
    "        grouping = df.loc[df['language_code'] == wiki].groupby('language_code')['page_id'].apply(pd.DataFrame)\n",
    "        ids = tuple(list(grouping[wiki]))\n",
    "        _id_ = grouping.reset_index(drop=True).iloc[0][0]\n",
    "        language_code = wiki\n",
    "        pageviews_results = spark.run(pv_indonesia_users_july.format(ids=ids, language_code=language_code))                \n",
    "        pageviews_all_results = spark.run(pv_all_users_july.format(ids=ids, language_code=language_code)) \n",
    "        pageview_articles.append(pageviews_results)\n",
    "        pageview_all_articles.append(pageviews_all_results)\n",
    "    \n",
    "    return(pageview_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pageviews_hive(articles)\n",
    "pv_id_query_data = pd.concat(pageview_articles)\n",
    "pv_all_query_data = pd.concat(pageviews_all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_id_query_data['language_code'] = pv_id_query_data['project'].str.split('.').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_id_query_data.to_csv(\"../../data/raw/articles/2019/query_results/content_quality/per_wiki_full/Indonesia/july_incountry_pageviews.csv\", sep=',', encoding = 'utf-8', index=False) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pv_id_query_data=pd.read_csv(\"../../data/raw/articles/2019/query_results/content_quality/per_wiki_full/Indonesia/july_incountry_pageviews.csv\", sep=',', encoding = 'utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_df = pd.merge(pv_id_query_data, articles, on=['language_code', 'page_id', 'page_title'], how='right').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_df.to_csv(\"../../data/raw/articles/2019/query_results/content_quality/per_wiki_full/Indonesia/articles_w_july_incountry_pageviews.csv\", sep=',', encoding = 'utf-8', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get pageviews for GLOW articles in GLOW Hive table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_india_users_feb = spark.run(\"\"\"\n",
    "SELECT \n",
    "  gta.database_code AS wikicode,\n",
    "  gta.page_id,\n",
    "  gta.page_title,\n",
    "  SUM(view_count) as feb_view_count_internal\n",
    "FROM florez.glow_tiger_articles gta\n",
    "LEFT JOIN canonical_data.wikis cdw\n",
    "    ON cdw.database_code = gta.database_code\n",
    "LEFT JOIN wmf.pageview_hourly pvh\n",
    "    ON gta.page_id = pvh.page_id\n",
    "    AND CONCAT(cdw.language_code, '.', cdw.database_group) = pvh.project \n",
    "    AND pvh.year = 2020\n",
    "    AND pvh.month = 2\n",
    "WHERE\n",
    "    pvh.agent_type='user'\n",
    "    AND pvh.country_code = 'IN'\n",
    "GROUP BY \n",
    "  gta.database_code, gta.page_id, gta.page_title\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_all_users_feb = spark.run(\"\"\"\n",
    "SELECT \n",
    "  gta.database_code AS wikicode,\n",
    "  gta.page_id,\n",
    "  gta.page_title,\n",
    "  SUM(view_count) as feb_view_count_global\n",
    "FROM florez.glow_tiger_articles gta\n",
    "LEFT JOIN canonical_data.wikis cdw\n",
    "    ON cdw.database_code = gta.database_code\n",
    "LEFT JOIN wmf.pageview_hourly pvh\n",
    "    ON gta.page_id = pvh.page_id\n",
    "    AND CONCAT(cdw.language_code, '.', cdw.database_group) = pvh.project \n",
    "    AND pvh.year = 2020\n",
    "    AND pvh.month = 2\n",
    "WHERE\n",
    "    pvh.agent_type='user'\n",
    "GROUP BY \n",
    "    gta.database_code, gta.page_id, gta.page_title\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_all_users_feb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_df = pd.merge(pv_all_users_feb, pv_india_users_feb, on=['database_code', 'page_id', 'page_title'], how = 'outer').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_df.to_csv(\"../../data/processed/query_results/content_quality/pv.csv\", sep=',', encoding = 'utf-8', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with full df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_frame_updated = pd.read_csv(\"../../data/processed/query_results/content_quality/b1_final_frame_updated.csv\", sep=',', encoding = 'utf-8', parse_dates=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_frame_updated_pv  = pd.merge(pv_df, final_frame_updated, on=['wikicode', 'page_id', 'page_title'], how = 'right').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_frame_updated_pv.to_csv(\"../../data/processed/query_results/content_quality/b3_final_frame_updated_pv.csv\", sep=',', encoding = 'utf-8', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_all_users_feb = spark.run(\"\"\"\n",
    "SELECT \n",
    "  gta.database_code AS wikicode,\n",
    "  gta.page_id,\n",
    "  gta.page_title,\n",
    "  SUM(view_count) as feb_view_count_global\n",
    "FROM florez.glow_tiger_articles gta\n",
    "LEFT JOIN canonical_data.wikis cdw\n",
    "    ON cdw.database_code = gta.database_code\n",
    "LEFT JOIN wmf.pageview_hourly pvh\n",
    "    ON gta.page_id = pvh.page_id\n",
    "    AND CONCAT(cdw.language_code, '.', cdw.database_group) = pvh.project \n",
    "    AND pvh.year = 2020\n",
    "    AND pvh.month = 2\n",
    "WHERE\n",
    "    pvh.agent_type='user'\n",
    "GROUP BY \n",
    "    gta.database_code, gta.page_id, gta.page_title\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feb_global_views_referrer = spark.run(\"\"\"\n",
    "SELECT \n",
    "  gta.database_code AS wikicode,\n",
    "  gta.page_id,\n",
    "  gta.page_title,\n",
    "  SUM(view_count) as feb_view_count_global,\n",
    "  referer_class\n",
    "FROM florez.glow_tiger_articles gta\n",
    "LEFT JOIN canonical_data.wikis cdw\n",
    "    ON cdw.database_code = gta.database_code\n",
    "LEFT JOIN wmf.pageview_hourly pvh\n",
    "    ON gta.page_id = pvh.page_id\n",
    "    AND CONCAT(cdw.language_code, '.', cdw.database_group) = pvh.project \n",
    "    AND pvh.year = 2020\n",
    "    AND pvh.month = 2\n",
    "WHERE\n",
    "    pvh.agent_type='user'\n",
    "GROUP BY \n",
    "    gta.database_code, gta.page_id, gta.page_title, referer_class\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
