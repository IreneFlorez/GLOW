{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOW - Setup: Collect Baselines - monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents  <a class=\"anchor\" id=\"toc\"></a>\n",
    "\n",
    "* [GLOW Wiki Baselines](#top)\n",
    "\n",
    "    1. [Editors](#editors)\n",
    "        1. [Editors](#editors_monthly)\n",
    "        2. [Monthly Active Editors](#editors_active)\n",
    "        3. [Monthly New Editors](#editors_new)\n",
    "        4. [New editor retention](#new_editor_retention)\n",
    "    2. [Articles](#articles)\n",
    "        1. [Articles Count by wiki](#articles_count) \n",
    "        2. [New Articles](#new_articles)\n",
    "        3. [Edits to existing articles](#article_edits)\n",
    "        4. [New articles: by date/exp/survival](#new_articles_filtered)\n",
    "    3. [Readers](#readers)\n",
    "        1. [Pageviews](#pageviews_detailed)\n",
    "    4. [Geo](#stage1b)\n",
    "        1. [Monthly Unique Devices](#editors_activity_countries)\n",
    "        2. [Edits geolocated](#editors_activity_countries)\n",
    "        3. [Editors geolocated](#editors_activity_countries)\n",
    "        4. [Pageviews across countries & wikis](#pageviews)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Averages Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Devices <a class=\"anchor\" id=\"article_detail\"></a>\n",
    "[Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monthly Unique Devices <a class=\"anchor\" id=\"devices\"></a>\n",
    "[Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mca_uds_r = '''\n",
    "SELECT\n",
    "    regexp_replace(\n",
    "        regexp_replace(\n",
    "            regexp_replace(domain, \"zero\\\\\\\\.\", \"\"),\n",
    "        '^m\\\\\\\\.', ''),\n",
    "    '\\\\\\\\.m\\\\\\\\.', '.') AS domain_name,\n",
    "  SUM(uniques_estimate) / 12 AS monthly_unique_devices\n",
    "FROM wmf.unique_devices_per_domain_monthly\n",
    "WHERE \n",
    "    CONCAT(year,LPAD(month,2,'0')) >= ({contest_start_dt_12m_pre_pv})\n",
    "    AND CONCAT(year,LPAD(month,2,'0')) < ({contest_start_dt_pv})\n",
    "    AND country_code IN ('IN')\n",
    "GROUP BY    \n",
    "    regexp_replace(\n",
    "        regexp_replace(\n",
    "            regexp_replace(domain, \"zero\\\\\\\\.\", \"\"),\n",
    "        '^m\\\\\\\\.', ''),\n",
    "    '\\\\\\\\.m\\\\\\\\.', '.')\n",
    "''' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikis<a class=\"anchor\" id=\"editors\"></a>\n",
    "[Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#canonical data in hive\n",
    "#https://github.com/wikimedia-research/canonical-data/blob/master/countries.csv\n",
    "countries_r = '''\n",
    "SELECT\n",
    "  name, \n",
    "  iso_code\n",
    "FROM canonical_data.countries\n",
    "WHERE name in ({glow_countries})\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all content wikis\n",
    "#https://github.com/wikimedia-research/canonical-data/blob/master/countries.csv\n",
    "wikis_r = '''\n",
    "SELECT\n",
    "  database_code,\n",
    "  database_group AS project_code,\n",
    "  language_code,\n",
    "  language_name,\n",
    "  english_name as wiki_name,\n",
    "  CONCAT(\"https://\", domain_name) AS domain_name\n",
    "FROM canonical_data.wikis\n",
    "WHERE\n",
    "  database_group in (\"mediawiki\", \"wikidata\", \"wikipedia\") \n",
    "  AND status = \"open\" \n",
    "  AND visibility = \"public\" \n",
    "  AND editability = \"public\"\n",
    "  AND database_code IN ({india_wiki_dbs})\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Editors<a class=\"anchor\" id=\"editors\"></a>\n",
    "[Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monthly editors & monthly new <a class=\"anchor\" id=\"editors_monthly\"></a>\n",
    "[Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted from:\n",
    "#https://github.com/wikimedia-research/wiki-segmentation\n",
    "#https://github.com/wikimedia-research/Editing-movement-metrics\n",
    "\n",
    "mce_r = '''\n",
    "SELECT\n",
    "    wiki AS database_code,\n",
    "    COUNT(*) / 12 AS monthly_editors,\n",
    "    sum(CAST(TRUNC(user_registration, 'MM') = TRUNC(month, 'MM') AS INT))/ 12 AS monthly_new_editors\n",
    "FROM cchen.editor_month\n",
    "WHERE\n",
    "    month >= \"{contest_start_dt_13m_pre}\"\n",
    "    AND month < \"{contest_start_dt}\"\n",
    "    AND wiki IN ({india_wiki_dbs}) \n",
    "    AND user_id != 0 \n",
    "    AND bot_by_group = FALSE\n",
    "    AND (user_name not regexp \"bot\\\\b\" or user_name in (\"Paucabot\", \"Niabot\", \"Marbot\"))\n",
    "GROUP BY wiki\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monthly New Active Editors & monthly active editors <a class=\"anchor\" id=\"editors_active\"></a>\n",
    "[Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#monthly active editors\n",
    "#adapted from:\n",
    "#https://github.com/wikimedia-research/wiki-segmentation\n",
    "#https://github.com/wikimedia-research/Editing-movement-metrics\n",
    "\n",
    "mnae_r = '''\n",
    "SELECT\n",
    "    wiki AS database_code,\n",
    "    COUNT(*) / 12 AS monthly_active_editors,\n",
    "    SUM(\n",
    "        CAST(TRUNC(user_registration, 'MM') = TRUNC(month, 'MM') AS INT)\n",
    "        )/ 12 AS monthly_new_active_editors\n",
    "FROM cchen.editor_month\n",
    "WHERE\n",
    "    content_edits >= 5 \n",
    "    AND month >= \"{contest_start_dt_13m_pre}\"\n",
    "    AND month < \"{contest_start_dt}\" \n",
    "    AND wiki IN ({india_wiki_dbs}) \n",
    "    AND user_id != 0 \n",
    "    AND bot_by_group = FALSE \n",
    "    AND (user_name not regexp \"bot\\\\b\" or user_name in (\"Paucabot\", \"Niabot\", \"Marbot\"))    \n",
    "GROUP BY wiki\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monthly Editors - including group of big wikis <a class=\"anchor\" id=\"editors_active\"></a>\n",
    "[Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_r = '''\n",
    "SELECT\n",
    "    em.wiki AS database_code,\n",
    "    COUNT(*) / 12 AS indic_editors_on_big_wikis_m\n",
    "FROM cchen.editor_month em\n",
    "WHERE\n",
    "    em.month >= \"{contest_start_dt_13m_pre}\"\n",
    "    AND em.month < \"{contest_start_dt}\"\n",
    "    AND em.wiki IN {wikis_big} \n",
    "    AND em.user_id != 0 \n",
    "    AND em.bot_by_group = FALSE\n",
    "    AND (em.user_name not regexp \"bot\\\\b\" or em.user_name in (\"Paucabot\", \"Niabot\", \"Marbot\"))  \n",
    "GROUP BY em.wiki\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monthly New Editors <a class=\"anchor\" id=\"editors_new\"></a>\n",
    "[Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#monthly new editors\n",
    "\n",
    "#adapted from:\n",
    "#https://github.com/wikimedia-research/wiki-segmentation\n",
    "\n",
    "mne_r = '''\n",
    "select\n",
    "    wiki AS database_code,\n",
    "    sum(CAST(TRUNC(user_registration, 'MM') = TRUNC(month, 'MM') AS INT))/ 12 AS monthly_new_editors\n",
    "from neilpquinn.editor_month\n",
    "where\n",
    "    month >= \"{contest_start_dt_12m_pre_FULL}\"\n",
    "    AND month < \"{TODAY_DATE_FULL}\" \n",
    "    AND wiki IN ({india_wiki_dbs})\n",
    "    AND user_id != 0\n",
    "    AND (user_name not regexp \"bot\\\\b\" or user_name in (\"Paucabot\", \"Niabot\", \"Marbot\"))\n",
    "group by wiki\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New editor retention <a class=\"anchor\" id=\"new_editor_retention\"></a>\n",
    "[Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#adapted from:\n",
    "#https://github.com/wikimedia-research/wiki-segmentation\n",
    "#https://github.com/wikimedia-research/Editing-movement-metrics\n",
    "\n",
    "ner_r = '''\n",
    "select \n",
    "    wiki AS database_code,\n",
    "    sum(cast(2nd_month_edits >= 1 as int)) / sum(cast(1st_month_edits >= 1 as int)) AS new_editor_retention\n",
    "from neilpquinn.new_editors\n",
    "where \n",
    "    cohort >= \"{contest_start_dt_12m_pre}\"\n",
    "    AND cohort < \"{TODAY_DATE}\"\n",
    "    AND wiki IN ({india_wiki_dbs})\n",
    "group by wiki\n",
    "limit 1000\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(\"queries/new_editor_retention.hql\") as f:\n",
    "    q = f.read()\n",
    "\n",
    "ner = wmf.hive.run(\n",
    "    q.format(start = \"{contest_start_dt_12m_pre}\", end = \"{TODAY_DATE}\").format(**query_vars))\n",
    "\n",
    "##ner = x where x in IN ({india_wiki_dbs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readers<a class=\"anchor\" id=\"readers\"></a>\n",
    "[Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PageViews by referer_class and access_method <a class=\"anchor\" id=\"pageviews_detailed\"></a>\n",
    "[Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_rc_r = '''\n",
    "SELECT \n",
    "  country_code,\n",
    "  project,\n",
    "  SUM(view_count) as view_count,\n",
    "  referer_class,\n",
    "  CONCAT(year,LPAD(month,2,'0'),LPAD(day,2,'0')) AS view_date\n",
    "FROM wmf.pageview_hourly\n",
    "WHERE\n",
    "  CONCAT(year,LPAD(month,2,'0')) >= {contest_start_dt_12m_pre_pv}\n",
    "  AND CONCAT(year,LPAD(month,2,'0')) < {contest_start_dt_next_m_pv}\n",
    "  AND agent_type='user'\n",
    "  AND country_code =  'IN'\n",
    "  AND project IN ({india_wiki_projects})\n",
    "GROUP BY \n",
    "  country_code, project, referer_class, year, month, day\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_all_r = '''\n",
    "SELECT \n",
    "  country_code,\n",
    "  project,\n",
    "  SUM(view_count) as view_count,\n",
    "  referer_class,\n",
    "  CONCAT(year,LPAD(month,2,'0'),LPAD(day,2,'0')) AS view_date\n",
    "FROM wmf.pageview_hourly\n",
    "WHERE\n",
    "  CONCAT(year,LPAD(month,2,'0')) >= {contest_start_dt_12m_pre_pv}\n",
    "  AND CONCAT(year,LPAD(month,2,'0')) < {contest_start_dt_next_m_pv}\n",
    "  AND agent_type='user'\n",
    "  AND project IN ({india_wiki_projects})\n",
    "GROUP BY \n",
    "  country_code, project, referer_class, year, month, day\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#same as above but broken down by month, instead of just giving a sum\n",
    "\n",
    "\n",
    "pv_rc_r = '''\n",
    "SELECT \n",
    "  country_code,\n",
    "  project,\n",
    "  SUM(view_count)/12 as view_count,\n",
    "  referer_class,\n",
    "FROM wmf.pageview_hourly\n",
    "WHERE\n",
    "  CONCAT(year,LPAD(month,2,'0')) >= {contest_start_dt_12m_pre_pv}\n",
    "  AND CONCAT(year,LPAD(month,2,'0')) < {contest_end_dt_next_m_pv}\n",
    "  AND agent_type='user'\n",
    "  AND country_code = {india_country_codes}\n",
    "  AND project IN ({india_wiki_projects})\n",
    "GROUP BY \n",
    "  country_code, project, referer_class, year, month\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#https://github.com/wikimedia-research/Readers-core-metrics/blob/master/01_interactions_metrics.ipynb\n",
    "#https://wikitech.wikimedia.org/wiki/Analytics/Data_Lake/Traffic/Pageview_hourly\n",
    "pv_am_r = hive.run(\"\"\"\n",
    "SELECT \n",
    "  country_code,\n",
    "  project,\n",
    "  SUM(IF(access_method = 'mobile app', view_count, null)) AS apps,\n",
    "  SUM(IF(access_method = 'desktop', view_count, null)) AS desktop,\n",
    "  SUM(IF(access_method = 'mobile web', view_count, null)) AS mobileweb,\n",
    "  SUM(view_count) as total,\n",
    "  year, month\n",
    "FROM wmf.pageview_hourly\n",
    "WHERE\n",
    "  CONCAT(year,LPAD(month,2,'0')) >= {TODAY_DATE_pv}\n",
    "  AND CONCAT(year,LPAD(month,2,'0')) < {M2_START_DATE_pv}\n",
    "  AND agent_type='user'\n",
    "  AND country_code = {india_country_codes}\n",
    "  AND project IN ({india_wiki_projects})\n",
    "GROUP BY \n",
    "  country_code, project, year, month\n",
    "\"\"\".format(**query_vars))\n",
    "\n",
    "pv_am = pv_am_r.copy()\n",
    "pv_am"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#https://github.com/wikimedia-research/Readers-core-metrics/blob/master/01_interactions_metrics.ipynb\n",
    "#https://wikitech.wikimedia.org/wiki/Analytics/Data_Lake/Traffic/Pageview_hourly\n",
    "pv_am_detail_r = hive.run(\"\"\"\n",
    "SELECT \n",
    "  country_code,\n",
    "  project,\n",
    "  page_id,\n",
    "  referer_class,\n",
    "  access_method,\n",
    "  SUM(view_count) as am_total,\n",
    "  SUM(IF(access_method = 'mobile app', view_count, null)) AS apps,\n",
    "  SUM(IF(access_method = 'desktop', view_count, null)) AS desktop,\n",
    "  SUM(IF(access_method = 'mobile web', view_count, null)) AS mobileweb,\n",
    "  year, month\n",
    "FROM wmf.pageview_hourly\n",
    "  WHERE\n",
    "  CONCAT(year,LPAD(month,2,'0')) >= {TODAY_DATE_pv}\n",
    "  AND CONCAT(year,LPAD(month,2,'0')) < {M2_START_DATE_pv}\n",
    "  AND agent_type='user'\n",
    "  AND country_code = {india_country_codes}\n",
    "  AND page_id != 0\n",
    "  AND project IN ({india_wiki_projects})\n",
    "GROUP BY \n",
    "  country_code, project, page_id, referer_class, access_method, year, month\n",
    "\"\"\".format(**query_vars))\n",
    "\n",
    "pv_am_detail = pv_am_detail_r.copy()\n",
    "pv_am_detail.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Switching <a class=\"anchor\" id=\"language_switching\"></a>\n",
    "[Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#https://github.com/geohci/language-switching\n",
    "language_switching = hive.run(\"\"\"\n",
    "SELECT reflect('org.apache.commons.codec.digest.DigestUtils', 'sha512Hex', CONCAT(user_agent, client_ip, \"{SALT}\")) AS user,\n",
    "       concat(translate(normalized_host.project, '-', '_'), 'wiki') AS project,\n",
    "       COALESCE(pageview_info[\"page_title\"], \"EDITATTEMPT\") as page_title,\n",
    "       page_id AS page_id,\n",
    "       dt,\n",
    "       geocoded_data['country'] AS country\n",
    "  FROM wmf.webrequest \n",
    " WHERE normalized_host.project_family = \"wikipedia\"\n",
    "       AND ((is_pageview AND namespace_id = 0)\n",
    "            OR (uri_query LIKE '%action=edit%' OR uri_query LIKE '%action=visualeditor%'\n",
    "                OR uri_query LIKE '%&intestactions=edit&intestactionsdetail=full&uiprop=options%'))\n",
    "       AND agent_type = \"user\" \n",
    "       AND year = {YEAR} AND month = {MONTH} AND day = {DAY}\n",
    "       AND SUBSTR(ip, -1, 1) = {# FROM 0-9}\n",
    "\"\"\".format(**query_vars))\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Articles<a class=\"anchor\" id=\"editors\"></a>\n",
    "[Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New articles <a class=\"anchor\" id=\"new_articles\"></a>\n",
    "[Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted from https://github.com/wikimedia-research/2018-19-Language-annual-plan-metrics/blob/master/Language-metrics.ipynb\n",
    "#https://wikitech.wikimedia.org/wiki/Analytics/Data_Lake/Edits/Mediawiki_history\n",
    "#revision\tcreate = Making an edit\n",
    "# 6 months ≈ 26 weeks = 252 days\n",
    "# period below starts 2019/07 \n",
    "\n",
    "# Making the first edit to a page\n",
    "\n",
    "m_new_article_counts_r = ''' \n",
    "select\n",
    "    wiki AS database_code,\n",
    "    count(*)/12 as mon_new_articles\n",
    "from wmf.mediawiki_history mh\n",
    "left join event_sanitized.serversideaccountcreation ssac\n",
    "on\n",
    "    ssac.event.username = event_user_text and\n",
    "    ssac.year >= 0\n",
    "where\n",
    "    mh.snapshot = \"{MWH_SNAPSHOT}\"\n",
    "    AND mh.event_timestamp >= \"{contest_start_dt_12m_pre_FULL}\"\n",
    "    AND mh.event_timestamp < \"{contest_start_dt_FULL}\" \n",
    "    AND event_entity = \"revision\"\n",
    "    AND event_type = \"create\"\n",
    "    AND wiki in ({india_wiki_dbs})\n",
    "GROUP BY wiki\n",
    "''' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### avg_num_new_articles_edited <a class=\"anchor\" id=\"new_articles\"></a>\n",
    "[Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted from https://github.com/wikimedia-research/2018-19-Language-annual-plan-metrics/blob/master/Language-metrics.ipynb\n",
    "#https://wikitech.wikimedia.org/wiki/Analytics/Data_Lake/Edits/Mediawiki_history\n",
    "#page\tcreate = Making the first edit to a page\n",
    "\n",
    "#6 months ≈ 26 weeks = 252 days\n",
    "\n",
    "#Making the first edit to a page\n",
    "m_new_articles_edited_r = ''' \n",
    "SELECT\n",
    "    wiki_db AS database_code, \n",
    "    count(*)/12 AS mon_new_articles_edited\n",
    "FROM wmf.mediawiki_history mh\n",
    "WHERE\n",
    "    mh.snapshot = \"{MWH_SNAPSHOT}\" \n",
    "    AND mh.event_timestamp >= \"{contest_start_dt_12m_pre_FULL}\"\n",
    "    AND mh.event_timestamp < \"{contest_start_dt_FULL}\" \n",
    "    AND event_entity = \"page\"\n",
    "    AND event_type = \"create\"\n",
    "    AND wiki_db in ({india_wiki_dbs})\n",
    "GROUP BY wiki_db\n",
    "''' \n",
    "\n",
    "#AND ssac.webhost LIKE '%wikipedia.org'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Existing articles, recently edited <a class=\"anchor\" id=\"article_edits\"></a>\n",
    "[Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted from https://github.com/wikimedia-research/2018-19-Language-annual-plan-metrics/blob/master/Language-metrics.ipynb\n",
    "#https://wikitech.wikimedia.org/wiki/Analytics/Data_Lake/Edits/Mediawiki_history\n",
    "#6 months ≈ 26 weeks = 252 days\n",
    "#period below starts 2019/07 \n",
    "\n",
    "eae_r = ''' \n",
    "select\n",
    "    wiki_db AS database_code, \n",
    "    count(*)/12 as avg_n_existing_articles_edited\n",
    "from wmf.mediawiki_history mh\n",
    "where\n",
    "    mh.snapshot = \"{MWH_SNAPSHOT}\"  \n",
    "    AND mh.event_timestamp >= \"{contest_start_dt_12m_pre_FULL}\"\n",
    "    AND mh.event_timestamp < \"{contest_start_dt_FULL}\" \n",
    "    AND event_entity = \"revision\"\n",
    "    AND event_type = \"create\" \n",
    "    AND wiki_db in ({india_wiki_dbs})\n",
    "GROUP BY wiki_db\n",
    "''' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daily revisions by wiki <a class=\"anchor\" id=\"daily_wiki_revisions\"></a>\n",
    "[Back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Daily revisions by wiki\n",
    "\n",
    "#`dr` stands for \"daily revisions\"\n",
    "dra_r = ''' \n",
    "    select\n",
    "        wiki_db AS database_code, \n",
    "        sum(if(metric = \"daily_edits\", value, 0)) - sum(if(metric = \"daily_edits_by_bot_users\", value, 0))/5 as nonbot_revs\n",
    "    from wmf.mediawiki_metrics\n",
    "    where\n",
    "        snapshot = \"{MWH_SNAPSHOT}\" \n",
    "        AND dt >=\"{contest_start_dt_12m_pre_FULL}\"\n",
    "        AND dt <\"{contest_start_dt_FULL}\"\n",
    "        AND metric in (\"daily_edits\", \"daily_edits_by_bot_users\")\n",
    "        AND wiki_db IN ({india_wiki_dbs})\n",
    "    group by wiki_db\n",
    "''' "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
