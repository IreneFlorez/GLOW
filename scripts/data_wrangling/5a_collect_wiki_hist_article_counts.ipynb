{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pypi.org/project/chromedriver-binary/\n",
    "#https://sites.google.com/a/chromium.org/chromedriver/getting-started/chromeos\n",
    "#tools: https://chrome.google.com/webstore/detail/xpath-helper/hgimnogjllphhhkhlmebbmlgjoejdpjl?hl=en\n",
    "#https://chromedriver.chromium.org/\n",
    "import requests\n",
    "import string\n",
    "import pandas as pd\n",
    "from lxml import html\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from urllib.request import Request, urlopen\n",
    "import time\n",
    "import re\n",
    "import os\n",
    " \n",
    "from selenium import webdriver\n",
    "import chromedriver_binary  # Adds chromedriver binary to path\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument('--headless')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get urls to query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run on local machine\n",
    "#/Documents/projects/wikimedia/_data_collection/collect_wiki_article_counts.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consider https://meta.wikimedia.org/wiki/List_of_Wikipedias/Table to be the ultimate source of truth on wiki counts\n",
    "\n",
    "#use the api https://www.mediawiki.org/wiki/API:Revisions\n",
    "#to get revid's for pages related to https://meta.wikimedia.org/w/index.php?title=List_of_Wikipedias/Table&action=history\n",
    "\n",
    "S = requests.Session()\n",
    "\n",
    "URL = \"https://meta.wikimedia.org/w/api.php\"\n",
    "\n",
    "PARAMS = {\n",
    "    \"action\": \"query\",\n",
    "    \"prop\": \"revisions\",\n",
    "    \"titles\": \"List of Wikipedias/Table\",\n",
    "    \"rvprop\": \"timestamp|ids\",\n",
    "    \"rvdir\": \"newer\",\n",
    "    \"rvstart\": \"2019-10-01T00:00:00.000Z\",\n",
    "    \"formatversion\": \"2\",\n",
    "    \"format\": \"json\",\n",
    "    \"rvlimit\": \"500\",\n",
    "}\n",
    "\n",
    "R = S.get(url=URL, params=PARAMS)\n",
    "DATA = R.json()\n",
    "\n",
    "for d in DATA['query']['pages']:\n",
    "    for k, v, in d.items():\n",
    "        inner = k, v\n",
    "        res = inner[1]\n",
    "\n",
    "rev_id_list = [i['revid'] for i in res]\n",
    "rev_df = pd.DataFrame(res)\n",
    "\n",
    "#alternate solution if you need to bypass the above:\n",
    "#results = pd.DataFrame(DATA['query']['pages'])\n",
    "#tmp = results.explode('revisions')\n",
    "#rev_df = pd.DataFrame(list(tmp.pop('revisions')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format the timestamp column to datetime\n",
    "rev_df['timestamp'] = pd.to_datetime(rev_df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy the df just in case\n",
    "df = rev_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab only one revid per month\n",
    "df['year'] = df.timestamp.map(lambda x: x.year)\n",
    "df['month'] = df.timestamp.map(lambda x: x.month)\n",
    "df['day'] = df.timestamp.map(lambda x: x.day)\n",
    "select_revs = df.sort_values(['year', 'month']).groupby(['year', 'month']).first()\n",
    "select_revs.reset_index();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the two main files to csv format\n",
    "select_revs.to_csv('rev_ids_2019_2020_select.csv', sep=',', encoding = 'utf-8', index=False) #only the first rev id in each month\n",
    "df.to_csv('rev_ids_2019_2020_all', sep=',', encoding = 'utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list out of rev ids, just in case that's helpful\n",
    "rev_ids_to_query = select_revs['revid'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add prefix to rev id column\n",
    "df2= select_revs.copy()\n",
    "prefix = 'https://meta.wikimedia.org/w/index.php?title=List_of_Wikipedias/Table&direction=prev&oldid='\n",
    "df2['revid'] = prefix + df2['revid'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list our of urls\n",
    "urls_to_query = df2['revid'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Article Count per wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape article counts by language\n",
    "#pull language name, date of revision, article count on that date of revision\n",
    "language_list = ['Urdu', 'Hindi','Kannada', 'Malayalam', 'Marathi', 'Odia', 'Punjabi', 'Western Punjabi', 'Santali', 'Sanskrit', 'Tamil', 'Tulu', 'Telugu', 'Assamese', 'Bangla', 'Gujarati']\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "ac = []\n",
    "\n",
    "def getRows():\n",
    "        for name in language_list:\n",
    "            #get year, label, wiki_name, art_count\n",
    "            print(URL)\n",
    "            ac_xpath = \"//a[text()='\" + str(name) + \"']/parent::td//following-sibling::td[3]/a\"\n",
    "            wiki_xpath = \"//a[text()='\" + str(name) + \"']/parent::td\" \n",
    "            date_xpath =\"//*[@id='mw-revision-date']\"\n",
    "            \n",
    "            ac_dict = {}\n",
    "            try:\n",
    "                get_date = driver.find_element_by_xpath(date_xpath).text\n",
    "                get_wiki_name = driver.find_elements_by_xpath (wiki_xpath)\n",
    "                get_article_count = driver.find_elements_by_xpath (ac_xpath)\n",
    "            \n",
    "            \n",
    "                ac_dict['date'] = date = get_date\n",
    "                ac_dict['lang'] = \"\".join([element.text for element in get_wiki_name]) \n",
    "                ac_dict['count'] = \"\".join([element.text for element in get_article_count]) \n",
    "            \n",
    "            except Exception:\n",
    "                pass\n",
    "            \n",
    "           \n",
    "            #print(ac_dict)\n",
    "            t_ac.append(ac_dict.copy())\n",
    "\n",
    "for URL in urls_to_query:\n",
    "    #driver = webdriver.Chrome()\n",
    "    driver.get(URL)\n",
    "    time.sleep(10)\n",
    "    \n",
    "    t_ac = []\n",
    "    getRows()\n",
    "    ac.append(t_ac.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_results = pd.DataFrame(ac).T\n",
    "raw_results.columns=raw_results.columns//1\n",
    "lang_count_results = pd.concat([pd.DataFrame(x.values) for _,x in raw_results.groupby(level=0,axis=1)]).dropna(axis=0,thresh=1)\n",
    "wiki_art_count_results = lang_count_results[0].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wiki_art_count_results.to_csv('../../data/processed/query_results/regional_counts/wiki_counts_India_GLOW_2016_2019.csv') \n",
    "wiki_art_count_results.to_csv('../../data/processed/query_results/regional_counts/wiki_counts_India_GLOW_2019_2020.csv', sep=',', encoding = 'utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
