{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using wmfdata 0.1.0 (latest).\n",
      "\n",
      "You can find the source for `wmfdata` at https://github.com/neilpquinn/wmfdata\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "import wmfdata as wmf\n",
    "from wmfdata import charting, mariadb, hive\n",
    "from wmfdata.utils import pct_str, pd_display_all\n",
    "from urllib.parse import unquote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/raw/articles/2019/N_India_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add wiki_db column for querying\n",
    "df['wiki_db'] = df['Language']+'wiki'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "contest_titles_denormalized = tuple(list(df['Articles']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_vars = dict(\n",
    "    contest_titles_denormalized = contest_titles_denormalized,\n",
    "    wiki_dbs = wiki_dbs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get qids \n",
    "qid_r = wmf.mariadb.run(\"\"\"\n",
    "SELECT\n",
    "  ips_site_page AS article,\n",
    "  ips_item_id AS QID\n",
    "FROM  wb_items_per_site  \n",
    "WHERE ips_site_id IN {wiki_dbs} \n",
    "      AND ips_site_page IN {contest_titles_denormalized}\n",
    "\"\"\".format(**article_vars), \"wikidatawiki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get clean list\n",
    "\n",
    "#merge in the clean list into the df\n",
    "df_w_ids = pd.merge(df, qid_r[['article', 'QID']], how=\"left\", left_on=['Articles'], right_on=['article']).drop('article', axis=1)\n",
    "\n",
    "#CLEAN DF - ready to use, drop na, drop all dupes\n",
    "df_w_ids_no_nulls = df_w_ids[df_w_ids['QID'].notna()]\n",
    "df_w_ids_clean = df_w_ids_no_nulls.drop_duplicates(subset=['Language', 'Articles', 'wiki_db', 'QID'], keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MISSING DF - to add data\n",
    "articles_w_QID_missing = df_w_ids[df_w_ids['QID'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify dupes \n",
    "#articles_w_QID_duplicated = df_w_ids_no_nulls[df_w_ids_no_nulls.duplicated(subset=['Language', 'Articles', 'wiki_db', 'QID'], keep=False)]\n",
    "\n",
    "#keep only first instance of dupes of full row duplicates\n",
    "articles_w_QID_duplicated = df_w_ids_no_nulls[df_w_ids_no_nulls.duplicated(subset=['Language', 'Articles', 'wiki_db', 'QID'], keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MISSING DF - to add data\n",
    "articles_w_QID_missing\n",
    "\n",
    "#DUPES DF - to clean \n",
    "articles_w_QID_duplicated\n",
    "\n",
    "#CLEAN DF - ready to use\n",
    "df_w_ids_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated = articles_w_QID_duplicated.append(df_w_ids_clean)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "articles_w_QID_missing.sample(8)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_updated.sample(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_w_QID_missing.to_csv(\"../../data/raw/articles/2019/articles_QID_missing.csv\", sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated.to_csv(\"../../data/raw/articles/2019/contest_titles_n_updated.csv\", sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
